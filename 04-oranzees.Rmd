---
title: "Oranzees model (04)"
author: "Alberto Acerbi"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This R markdown file documents the development of the Oranzees model (it continues from [03-oranzees.html](03-oranzees.html)). The code-only version to run the model is in the file [main.R](main.R) in the same repository.

## Testing the mockup function

We should first run the code for all the function we wrote, without showing it in the html rendering (remember the option`echo=FALSE`).

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(scales)

set_oranzees_world <- function(alpha_g, alpha_e) {
  list_pop <- c("Uossob", "Iat Forest", "Ebmog", "Elaham", "Elabik", "Ognodub")
  output <- tibble(
    population = rep(list_pop, each = 38),
    behaviour = as.factor(rep(1:38, 6)),
    type = rep(c(rep("social", 16), rep("food-related", 22)), 6),
    category = rep(c(
      rep("play", 4), rep("display", 4), rep("groom", 4), rep("courthsip", 4),
      "A", "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "D", "D", "D", "E", "E", "F", "F", "G", "H", "I", "J"
    ), 6),
    nutrient = rep(c(rep(NA, 16), "Y", "Y", "Y", "Y", "Z", "Z", "Z", "Z", "Y", "Y", "Y", "Z", "Z", "Z", "Y", "Y", "Z", "Z", "Y", "Z", "Y", "Z"), 6),
    p_g = rep(NA, 38 * 6),
    p_e = rep(NA, 38 * 6)
  )

  env_or_x <- c(220, 230, 700, 705, 710, 750)
  env_or_y <- c(660, 610, 450, 430, 510, 550)

  # genetic predispositions:
  x_g <- sample(1:1000, 38)
  y_g <- sample(1:1000, 38)

  # ecological availability:
  x_e <- sample(1:1000, 38)
  y_e <- sample(1:1000, 38)

  for (behav in 1:38) {
    output[output$behaviour == behav, ]$p_g <- 1 - rescale(sqrt((x_g[behav] - env_or_x)^2 + (y_g[behav] - env_or_y)^2), to = c(1 - alpha_g, alpha_g))

    if (behav > 16) {
      output[output$behaviour == behav, ]$p_e <- 1 - rescale(sqrt((x_e[behav] - env_or_x)^2 + (y_e[behav] - env_or_y)^2), to = c(1 - alpha_e, alpha_e))
    }
  }
  # return the tibble:
  output
}

update_demography <- function(pop) {
  pop[, 39] <- pop[, 39] + 1
  pop[pop[, 39] >= 720, ] <- 0
  old <- which(pop[, 39] > 300)
  dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
  pop[old[dead], ] <- 0
  pop
}

update_social_behaviours <- function(pop, test_world) {
  N <- dim(pop)[1]
  state <- ((rowSums(pop[, 1:4]) >= 1) + (rowSums(pop[, 5:8]) >= 1) + (rowSums(pop[, 9:12]) >= 1) + (rowSums(pop[, 13:16]) >= 1)) / 4
  p_state <- runif(N) < rnorm(N, mean = 1 - state, sd = 0.05)
  p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
  p_peering[p_peering < 0] <- 0
  innovation_i <- sample(1:16, N, prob = p_peering, replace = TRUE)
  p_innovate <- runif(N) < test_world$p_g[innovation_i] * p_state
  for (i in (1:N)[p_innovate]) {
    pop[i, innovation_i[i]] <- 1
  }
  pop
}

update_food_behaviours <- function(pop, test_world) {
  N <- dim(pop)[1]
  nut_y <- (rowSums(pop[, 17:20]) >= 1) + (rowSums(pop[, 25:27]) >= 1) + (rowSums(pop[, 31:32]) >= 1) + pop[, 35] + pop[, 37]
  nut_z <- (rowSums(pop[, 21:24]) >= 1) + (rowSums(pop[, 28:30]) >= 1) + (rowSums(pop[, 33:34]) >= 1) + pop[, 36] + pop[, 38]
  state <- (nut_y + nut_z - abs(nut_y - nut_z)) / 10
  p_state <- runif(N) < rnorm(N, mean = 1 - state, sd = 0.05)
  p_peering <- rnorm(22, mean = colSums(pop[, 17:38]), sd = 1)
  p_peering[p_peering < 0] <- 0
  innovation_i <- sample(17:38, N, prob = p_peering, replace = TRUE)
  p_innovate <- runif(N) < test_world$p_g[innovation_i] * test_world$p_e[innovation_i] * p_state
  for (i in (1:N)[p_innovate]) {
    pop[i, innovation_i[i]] <- 1
  }
  pop
}

###
### MAIN FUNCTION
###

mockup_oranzees <- function(t_max, alpha_g, alpha_e, init_world, n_run) {
  N <- 100

  if (n_run == 1) {
    output <- matrix(nrow = t_max, ncol = 38)
  }
  else {
    output <- matrix(nrow = n_run, ncol = 38)
  }

  oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
  test_world <- oranzees_world %>%
    filter(population == "Uossob")

  for (run in 1:n_run) {
    pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)
    if (init_world) {
      oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
      test_world <- oranzees_world %>%
        filter(population == "Uossob")
    }
    # start simulation here:
    for (t in 1:t_max) {
      if (n_run == 1) {
        output[t, ] <- colSums(pop[, 1:38])
      }
      pop <- update_demography(pop)
      pop <- update_social_behaviours(pop, test_world)
      pop <- update_food_behaviours(pop, test_world)
    }
    if (n_run > 1) {
      output[run, ] <- colSums(pop[, 1:38])
    }
  }
  output
}
```

It is worth to recapitulate how the main function `mockup_oranzees()` works. The parameters `t_max`, `alpha_g`, and `alpha_e` set the values of these variables. If `init_world` is `TRUE`, oranzees' world is initalised before each run, if `FALSE` only before the first one (if there is only one run, it does not have any effect, because the world is always initalised at the beginning). `n_run` sets the number of runs, and also changes the output accordingly. If a single run, the output is the full history of the behaviours through time; if more than one, only the final state of the population, for each run. 

We can also wrap into functions the code to visaulise the results. For one run:

```{r}
plot_one_run <- function(my_test, t_max) {
  my_test <- gather(as_tibble(my_test), 1:38, key = "behaviour", value = "frequency")
  data_to_plot <- tibble(
    behaviour = my_test$behaviour,
    frequency = my_test$frequency,
    time = rep(1:t_max, 38),
    category = as_factor(c(
      rep("play", t_max * 4), rep("display", t_max * 4), rep("groom", t_max * 4), rep("courthsip", t_max * 4),
      rep("A", t_max * 4), rep("B", t_max * 4), rep("C", t_max * 3), rep("D", t_max * 3),
      rep("E", t_max * 2), rep("F", t_max * 2), rep("G", t_max), rep("H", t_max),
      rep("I", t_max), rep("J", t_max)
    ))
  )
  ggplot(data = data_to_plot) +
    geom_line(aes(x = time, y = frequency, color = behaviour)) +
    facet_wrap(~category) +
    theme_bw() +
    theme(legend.position = "none")
}
```

Thus, running and visualising a run is as simple as:

```{r warning=FALSE}
my_test <- mockup_oranzees(t_max = 12000, alpha_g = 0.7, alpha_e = 0.9, init_world = FALSE, n_run = 1)
plot_one_run(my_test = my_test, t_max = 12000)
```

Here the function to visualise multiple runs:

```{r message=FALSE}
library(reshape2)
plot_multiple_runs <- function(my_test, n_run) {
  as_tibble(melt(my_test, varnames = c("run", "behaviour"), value.name = "frequency")) %>%
    mutate(run = as_factor(run), behaviour = as_factor(behaviour)) %>%
    add_column(category = as_factor(c(
      rep("play", 4 * n_run), rep("display", 4 * n_run), rep("groom", 4 * n_run), rep("courthsip", 4 * n_run),
      rep("A", 4 * n_run), rep("B", 4 * n_run), rep("C", 3 * n_run), rep("D", 3 * n_run),
      rep("E", 2 * n_run), rep("F", 2 * n_run), rep("G", n_run), rep("H", n_run),
      rep("I", n_run), rep("J", n_run)
    ))) %>%
    ggplot() +
    geom_raster(aes(x = behaviour, y = run, fill = frequency)) +
    facet_wrap(~category, scales = "free") +
    scale_fill_gradient(low = "grey90", high = "red") +
    theme_bw()
}
```

Here the code to run, and visualise, multiple runs.

```{r}
my_test <- mockup_oranzees(t_max = 12000, alpha_g = 0.7, alpha_e = 0.9, init_world = FALSE, n_run = 10)
plot_multiple_runs(my_test = my_test, n_run = 10)
```

### The effect of the parameter $\alpha$

Let's start to examine more in detail the oranzees model as built so far. One first obvious factor that determines the final distribution of behaviours is the parameter $\alpha$. Let's have a look at one run with $\alpha_g=1$ and $\alpha_e=1$, i.e. the maximum effect of genetic and environmental constraints:  

```{r}
my_test <- mockup_oranzees(t_max = 12000, alpha_g = 1, alpha_e = 1, init_world = FALSE, n_run = 1)
plot_one_run(my_test = my_test, t_max = 12000)
```

And the opposite case, i.e., $\alpha_g=0.5$ and $\alpha_e=0.5$, thus no effect:

```{r}
my_test <- mockup_oranzees(t_max = 12000, alpha_g = 0.5, alpha_e = 0.5, init_world = FALSE, n_run = 1)
plot_one_run(my_test = my_test, t_max = 12000)
```

As expected, higher values of $\alpha$ creates 'cultures' where few traits are strongly majoritary in the population, with respect to our intermediate test situation, and lower values have the opposite effect. Another thing to notice is that we probably do not need to run our simulations until $t_{max}=12000$: to save time, in the next tests (involving several runs), we will use $t_{max}=6000$.

To test if what we observed from single runs is not due to any particular initialisation, we analyse now 100 runs, initialising each time the world (`init_world = TRUE`), for various values of $\alpha$. Let's start with $\alpha=0.5$. As before, we run the simulations only once, and we load the data here.

```{r eval=FALSE}
my_test <- mockup_oranzees(t_max = 6000, alpha_g = 0.5, alpha_e = 0.5, init_world = TRUE, n_run = 100)
write(t(my_test), file = "output/test_alpha=0.5.csv", ncolumns = 38)
```

We can use the same categories of Whiten et al., 1999, to see how many behaviours are categorised as 'customary', 'habitual', 'present', or 'absent'. We use for now custom boundaries (see the code below), as there is not a precise quantitative definition in Whiten et al. Of course, these can be changed for the final analysis. We also distinguish the results for social and food-related behaviours: 

```{r}
results <- as.matrix(read.table("output/test_alpha=0.5.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

cumulative_05 <- cumulative

ggplot(data = cumulative) +
  geom_bar(aes(x = category, y = n_behaviours/100), stat = 'identity') +
  facet_wrap(~type) +
  labs(title = "α = 0.5") +
  theme_bw() 
```

Let's do the same for other values of $\alpha$, until $\alpha=0.1$. We only show the plots in the output document, as the code is the same for all cases:

```{r echo=FALSE}
results <- as.matrix(read.table("output/test_alpha=0.6.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

ggplot(data = cumulative) +
  geom_bar(aes(x = category, y = n_behaviours/100), stat = 'identity') +
  facet_wrap(~type) +
  labs(title = "α = 0.6") +
  theme_bw() 

cumulative_06 <- cumulative

results <- as.matrix(read.table("output/test_alpha=0.7.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

ggplot(data = cumulative) +
  geom_bar(aes(x = category, y = n_behaviours/100), stat = 'identity') +
  facet_wrap(~type) +
  labs(title = "α = 0.7") +
  theme_bw() 

cumulative_07 <- cumulative

results <- as.matrix(read.table("output/test_alpha=0.8.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

ggplot(data = cumulative) +
  geom_bar(aes(x = category, y = n_behaviours/100), stat = 'identity') +
  facet_wrap(~type) +
  labs(title = "α = 0.8") +
  theme_bw() 

cumulative_08 <- cumulative

results <- as.matrix(read.table("output/test_alpha=0.9.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

ggplot(data = cumulative) +
  geom_bar(aes(x = category, y = n_behaviours/100), stat = 'identity') +
  facet_wrap(~type) +
  labs(title = "α = 0.9") +
  theme_bw() 

cumulative_09 <- cumulative

results <- as.matrix(read.table("output/test_alpha=1.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

ggplot(data = cumulative) +
  geom_bar(aes(x = category, y = n_behaviours/100), stat = 'identity') +
  facet_wrap(~type) +
  labs(title = "α = 1") +
  theme_bw() 

cumulative_1 <- cumulative

```

To summarise all:

```{r}
bind_rows(cumulative_05, cumulative_06, cumulative_07, cumulative_08, cumulative_09, cumulative_1) %>%
  add_column(alpha=c(rep(0.5, 8), rep(0.6, 8), rep(0.7, 8), rep(0.8, 8), rep(0.9, 8), rep(1, 8))) %>%
  ggplot(aes(x = alpha, y = n_behaviours/100, color = category)) +
    geom_point() +
    geom_line() +
    facet_wrap(~type) +
    theme_bw()
```

This plot shows a few interesting results. First, as we would expect, the effect of varying $\alpha$ is stronger for food-related than for social behviours. This is expected, because the former are constrained both by ecology and genes, while the latter only by genes. Second, when there are no constraints $\alpha=0.5$ all behaviours are present, but none of them is customary (and very few habitual). Whereas this is somewhat intuitive, we would expect social influence to have some effect on behaviours even when there are not other constraints. 

### The 'precision' of social influence

The probability of innovating a specific behaviour is given by genetic and environmental constraint as well as its frequency in the population. Common behaviours are more likely to be innovated. This should create, because of random drift, a situation in which some behaviours are more common than others. To study this effect, we need to modulate the standard deviation in the calculation of `p_peering` (see note at the end of [01-oranzees.html](01-oranzees.html)). 

Intuitively, low standard deviations will produce, also when there are not environmental or ecological constraints, 'cultures' with less, and customary, behaviours, because of random initial small differences. 

To test this, we should rewrite our functions adding a new parameter that specifies the standard deviation in the calculation of `p_peering`. Let's call it `sd_peering`. 

```{r echo=FALSE}
update_social_behaviours <- function(pop, test_world, sd_peering) {
  N <- dim(pop)[1]
  state <- ((rowSums(pop[, 1:4]) >= 1) + (rowSums(pop[, 5:8]) >= 1) + (rowSums(pop[, 9:12]) >= 1) + (rowSums(pop[, 13:16]) >= 1)) / 4
  p_state <- runif(N) < rnorm(N, mean = 1 - state, sd = 0.05)
  p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = sd_peering)
  p_peering[p_peering < 0] <- 0
  innovation_i <- sample(1:16, N, prob = p_peering, replace = TRUE)
  p_innovate <- runif(N) < test_world$p_g[innovation_i]  * p_state
  for (i in (1:N)[p_innovate]) {
    pop[i, innovation_i[i]] <- 1
  }
  pop
}  

update_food_behaviours <- function(pop, test_world, sd_peering) {
  N <- dim(pop)[1]
  nut_y <- (rowSums(pop[, 17:20])>=1) + (rowSums(pop[, 25:27])>=1) + (rowSums(pop[, 31:32])>=1) + pop[, 35] + pop[, 37]
  nut_z <- (rowSums(pop[, 21:24])>=1) + (rowSums(pop[, 28:30])>=1) + (rowSums(pop[, 33:34])>=1) + pop[, 36] + pop[, 38]
  state <- (nut_y + nut_z - abs(nut_y - nut_z)) / 10 
  p_state <- runif(N) < rnorm(N, mean = 1 - state, sd = 0.05)
  p_peering <- rnorm(22, mean = colSums(pop[, 17:38]), sd = sd_peering)
  p_peering[p_peering < 0] <- 0
  innovation_i <- sample(17:38, N, prob = p_peering, replace = TRUE)
  p_innovate <- runif(N) < test_world$p_g[innovation_i] * test_world$p_e[innovation_i] * p_state
  for (i in (1:N)[p_innovate]) {
    pop[i, innovation_i[i]] <- 1
  }
  pop
}

###
### MAIN FUNCTION
###

mockup_oranzees <- function(t_max, alpha_g, alpha_e, sd_peering, init_world, n_run) {
  
  N <- 100
  
  if(n_run == 1){
    output <- matrix(nrow = t_max, ncol = 38)
  }
  else{
    output <- matrix(nrow = n_run, ncol = 38)
  }
  
  oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
  test_world <- oranzees_world %>%
    filter(population == "Uossob")
  
  for(run in 1:n_run){
    pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)
    if (init_world) {
      oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
      test_world <- oranzees_world %>%
        filter(population == "Uossob")
    }
    # start simulation here:
    for (t in 1:t_max) {
      if(n_run == 1){
        output[t,] <- colSums(pop[, 1:38])
      }
      pop <- update_demography(pop)
      pop <- update_social_behaviours(pop, test_world, sd_peering)
      pop <- update_food_behaviours(pop, test_world, sd_peering)
    }
    if( n_run > 1){
      output[run, ] <- colSums(pop[, 1:38])
    }  
  }
  output
}
```

We can now call again the main function, for the case of $\alpha=0.5$, but for two lower values of `sd_peering`, i.e. 0.1, 0.01, 0.001 (as before, the data are saved beforehand):

```{R eval=FALSE}
my_test <- mockup_oranzees(t_max = 6000, alpha_g = 0.5, alpha_e = 0.5, sd_peering = 0.1, init_world = TRUE, n_run = 100)
write(t(my_test), file = "output/test_alpha=0.5_sd=0.1.csv", ncolumns = 38)

my_test <- mockup_oranzees(t_max = 6000, alpha_g = 0.5, alpha_e = 0.5, sd_peering = 0.01, init_world = TRUE, n_run = 100)
write(t(my_test), file = "output/test_alpha=0.5_sd=0.01.csv", ncolumns = 38)

my_test <- mockup_oranzees(t_max = 6000, alpha_g = 0.5, alpha_e = 0.5, sd_peering = 0.001, init_world = TRUE, n_run = 100)
write(t(my_test), file = "output/test_alpha=0.5_sd=0.001.csv", ncolumns = 38)
```

We can plot the results similarly to what we did for different $\alpha$, but comparing now the effect of `sd_peering` (code to upload the data in the Rmd document).

```{r echo=FALSE}
results <- as.matrix(read.table("output/test_alpha=0.5_sd=0.1.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

cumulative_05_01 <- cumulative

results <- as.matrix(read.table("output/test_alpha=0.5_sd=0.01.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

cumulative_05_001 <- cumulative

results <- as.matrix(read.table("output/test_alpha=0.5_sd=0.001.csv"))

cumulative <- tibble(category = as_factor(c("customary", "habitual", "present", "absent", "customary", "habitual", "present", "absent")),
                     type = as_factor(c(rep("social", 4), rep("food", 4))),
                     n_behaviours = c(sum(results[, 1:16]>=90), 
                                  sum(results[, 1:16]>=70 & results[, 1:16]<90), 
                                  sum(results[, 1:16]>=10 & results[, 1:16]<70), 
                                  sum(results[, 1:16]<10),
                                  sum(results[, 17:38]>=90), 
                                  sum(results[, 17:38]>=70 & results[, 17:38]<90), 
                                  sum(results[, 17:38]>=10 & results[, 17:38]<70), 
                                  sum(results[, 17:38]<10)))

cumulative_05_0001 <- cumulative
```

```{R}
cumulative <- bind_rows(cumulative_05, cumulative_05_01, cumulative_05_001, cumulative_05_0001) %>%
  add_column(sd=c(rep(1, 8), rep(0.1, 8), rep(0.01, 8), rep(0.001, 8)))

cumulative$sd <- factor(cumulative$sd, levels = c(1, 0.1, 0.01, 0.001))

ggplot(data = cumulative, aes(x = sd, y = n_behaviours/100, color = category, group = category)) +
  geom_point() +
  stat_summary(fun.y = mean, geom="line" ) +
  facet_wrap(~type) +
  theme_bw()
```

The effect of decreasing the noise in the observation is qualitatively the same of adding constraints (genetic or environmental) - compare this with the previous plot. This is an extreme scenario (with zero effect of genes, and, especially, no environmental constraints), and we can still obtain that some traits are absent and others are customary/habitual tuning `sd_peering`.

***

The documentation continues in [05-oranzees.html](05-oranzees.html)

