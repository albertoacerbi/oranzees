---
title: "Oranzees model"
author: "Alberto Acerbi"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This R markdown file documents the development of the Oranzees model. The code-only version to run the model is in the file *main.R* in the same repository.

## Spatial set-up

We first need to set-up a simulated environment where six populations of oranzees live at relative distances that are approximately similar to the six populations of chimpanzees described in Whiten et al., 1999. 

We use the R package [`imager`](https://dahtah.github.io/imager/imager.html) to process a capture from Figure 1 in Whiten et al., 1999.

```{r message = FALSE}
library(imager)
chimp_env <- load.image("material/Whiten_1999_cap.png")
plot(chimp_env)
box()
```

We manually process the image to have only the six points to which we are interested, and we also reverse the y-axis (in image processing starting from zero and go negative is standard, but this is not useful for us):

```{r}
chimp_env <- load.image("material/Whiten_1999_cap2.png")
plot(chimp_env, axes = F)
axis(1)
axis(2, at = seq(-100, 400, 100), labels = seq(500, 0, -100))
grid()
box()
```

Here are the approximate locations of the oranzees populations:

```{r}
env_or_x <- c(420, 430, 900, 905, 910, 950)
env_or_y <- c(360, 310, 150, 130, 210, 250)

plot(env_or_x, env_or_y, xlim = c(0, 1200), ylim = c(0, 500), pch = 21, bg = "red")
grid()
```

Just for visualisation purposes, here a plot with the same locations overimposed to a map of the imaginary 'Pongogea', where oranzees live. Notice the command `-env_or_y + 400` which move back to y coordinates to the reversed y-axis. The names of the sites are the reversed version of the names in Whiten et al., 1999 (e.g. 'Uossob' = 'Bossou', etc.)

```{r}
pongogea <- load.image("material/pongogea_cap.png")
plot(pongogea)
points(env_or_x, -env_or_y + 400, pch = 21, bg = "red", cex = 0.5)

text(100, 30, "Uossob", font = 2, cex = 0.9)
segments(180, 30, env_or_x[1], -env_or_y[1] + 400)

text(120, 270, "Iat Forest", font = 2, cex = 0.9)
segments(210, 270, env_or_x[2], -env_or_y[2] + 400)

text(540, 270, "Ebmog", font = 2, cex = 0.9)
segments(600, 270, env_or_x[3], -env_or_y[3] + 400)

text(1200, 270, "Elaham", font = 2, cex = 0.9)
segments(1120, 270, env_or_x[4], -env_or_y[4] + 400)

text(540, 30, "Elabik", font = 2, cex = 0.9)
segments(600, 30, env_or_x[5], -env_or_y[5] + 400)

text(1220, 30, "Ognodub", font = 2, cex = 0.9)
segments(1120, 30, env_or_x[6], -env_or_y[6] + 400)
```

For modelling convenience, we put these locations approximately in the centre of a 1000,1000 squared environment (what is important are the relative distances, not their absolute values):

```{r}
env_or_x <- env_or_x - 200
env_or_y <- env_or_y + 300

par(pty = "s")
plot(env_or_x, env_or_y, xlim = c(0, 1000), ylim = c(0, 1000), pch = 21, bg = "red")
grid()
```

***

## The behaviours

Following again Whiten et al., 1999, we consider 38 possible behaviours. We distinguish among 16 'social' and 22 'food-related' behaviours.


### Genetic propensity

We first implement the idea that the probability to acquire any of these behaviours depends (among other things) by what we call 'genetic propensity', and we model as a probability $p_g(0,1)$.

These probability is assigned randomly and independently to each behaviours. To assign it to the different populations we use a geographical gradient. For each behaviour, a random point is chosen in the Cartesian space and its distance to each population is calculated. This distance is then normalised between 0 and 1000. The actual probabilities are then calculated as $1-d_{norm}$.

Here an example:

```{r}
# generate the random point for the genetic propensity:
x_g <- sample(1:1000, 1)
y_g <- sample(1:1000, 1)

# calcualte the distance from the six populations:
d_g <- c()
for (i in 1:6) {
  d_g[i] <- sqrt((x_g - env_or_x[i])^2 + (y_g - env_or_y[i])^2)
}
```

Now we can see the random point we extracted:

```{r echo=FALSE}
c(x_g, y_g)
```

And the distances calculated:

```{r echo=FALSE}
d_g
```

We normalise the distance by 1000, and we then find the final probability subtracting from 1 (values that are below 0, i.e. population that were at more than 1000 units distance, are considered 0):

```{r}
d_g_norm <- d_g / 1000
p_g <- 1 - d_g_norm
p_g[p_g < 0] <- 0
```

Here are the final values for $p_g$:

```{r echo=FALSE}
p_g
```

An intuitive way to see this graphically is to use a gradient. The code is slightly more complicated, but we just need to run it once to visualise the effect. We first calculate the values of $p_g$ for all the points in the environment:

```{r}
gradient_g <- matrix(nrow = 1000, ncol = 1000)

for (i in 1:1000) {
  for (j in 1:1000) {
    gradient_g[i, j] <- sqrt((x_g - i)^2 + (y_g - j)^2)
  }
}
gradient_g <- 1 - gradient_g / 1000
gradient_g[gradient_g < 0] <- 0
```

And we then plot it, using the R package [`viridis`](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html), for the colour scale.

```{r message = FALSE}
library(viridis)
par(pty = "s")
image(1:1000, 1:1000, gradient_g, col = viridis(10), xlab = "env_or_x", ylab = "env_or_y")
contour(1:1000, 1:1000, gradient_g, add = TRUE)
points(env_or_x, env_or_y, pch = 21, bg = "red")
```

We can check that the $p_g$ values of the six different populations look like the ones we showed above, just before working on the visualisation (the order of the populations is from left to right on the x-axis). Remember, this means that population with higher values will be more genetically predisposed to acquire one of the 38 behaviours.

### Ecological availability

We define, together with genetic propensity, a similar variable $p_e(0,1)$, standing for ecological availability. Whereas the likelihood of acquiring all beahviours depends on $g_e$, ecological availability has influence only on food-related behaviours. Ecological availability can be thought as the probability of finding a resource, or its nutritional values, in one of the site.

ecological availability is implemented as genetic propensity, with the only difference that the distances are normalised by 500:

```{r}
x_e <- sample(1:1000, 1)
y_e <- sample(1:1000, 1)

d_e <- c()
for (i in 1:6) {
  d_e[i] <- sqrt((x_e - env_or_x[i])^2 + (y_e - env_or_y[i])^2)
}

d_e_norm <- d_e / 500
p_e <- 1 - d_e_norm
p_e[p_e < 0] <- 0
```

As before, here are the final values for $p_e$:

```{r echo=FALSE}
p_e
```

And we can visualise them, using the same technique:

```{r}
gradient_e <- matrix(nrow = 1000, ncol = 1000)

for (i in 1:1000) {
  for (j in 1:1000) {
    gradient_e[i, j] <- sqrt((x_e - i)^2 + (y_e - j)^2)
  }
}
gradient_e <- 1 - gradient_e / 500
gradient_e[gradient_e < 0] <- 0

par(pty = "s")
image(1:1000, 1:1000, gradient_e, col = magma(10), xlab = "env_or_x", ylab = "env_or_y")
contour(1:1000, 1:1000, gradient_e, add = TRUE)
points(env_or_x, env_or_y, pch = 21, bg = "red")
```

Again, we can check that the values in the plot correspond to the ones calculated above. The difference between the plot for genetic propensity and the plot for ecological availability illustrates the difference in the normalisation (1000 for the former and 500 for the latter). In the ecological availability plot, depending where the random point has been placed, it is more likely that some areas of the environment will be with $p_e=0$, including possibly some of our six populations. This reflects the fact that, for example, some raw materials can be available in a population, but not in another. The likelihood of $p_g=0$ is instead lower, reflecting that genetic constraints are less strong.


### Categories of behaviours

We model the idea that different behaviours can serve the same goal, so that if behaviour $1$ and $2$ serve the same goal, an individual performing $1$ will be unlikely to also perform $2$. 

In the case of social behaviours, we assume four categories of behaviours, each with four possible different behaviours, that serve the same goal, as illustrated here (notice the categories' names are purely indicative):

Category  |    |    |    | 
--------- |----|----|----|----
play      | 1  | 2  | 3  | 4
display   | 5  | 6  | 7  | 8
groom     | 9  | 10 | 11 | 12
courtship | 13 | 14 | 15 | 16

We do the same for food-related behaviours, with the difference that, for each 'goal' there is a variable number of behaviours, as such:

Category |    |    |    | 
---------|----|----|----|----
A        | 17 | 18 | 19 | 20
B        | 21 | 22 | 23 | 24
C        | 25 | 26 | 27 | 
D        | 28 | 29 | 30 | 
E        | 31 | 32 |    |
F        | 33 | 34 |    |
G        | 35 |    |    |
H        | 36 |    |    |
I        | 37 |    |    |
J        | 38 |    |    |

In addition, the categories of food-related behaviours are associated to two different 'nutrients'. The idea is that individuals need to balance their nutritional intake, so that their optimal diet consist in a roughly equal number of foodstuff for one and the other nutrient. Our final classification of food-related behaviours is:

Category |    |    |    |    | Nutrient
---------|----|----|----|----|---------
A        | 17 | 18 | 19 | 20 |    Y
B        | 21 | 22 | 23 | 24 |    Z
C        | 25 | 26 | 27 |    |    Y
D        | 28 | 29 | 30 |    |    Z
E        | 31 | 32 |    |    |    Y
F        | 33 | 34 |    |    |    Z
G        | 35 |    |    |    |    Y
H        | 36 |    |    |    |    Z
I        | 37 |    |    |    |    Y
J        | 38 |    |    |    |    Z 

***

## Setting-up the environment

We can now wrap everything up in a function `set_oranzees_environment()` that can be used independently from what we done so far, and that we will use in the code of the actual model (*main.R*):

```{r message=FALSE}
library(tidyverse)

set_oranzees_environment <- function() {
  list_pop <- c("Uossob", "Iat Forest", "Ebmog", "Elaham", "Elabik", "Ognodub")
  output <- tibble(
    population = rep(list_pop, each = 38),
    behaviour = as.factor(rep(1:38, 6)),
    type = rep(c(rep("social", 16), rep("food-related", 22)), 6),
    category = rep(c(
      rep("play", 4), rep("display", 4), rep("groom", 4), rep("courthsip", 4),
      "A", "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "D", "D", "D", "E", "E", "F", "F", "G", "H", "I", "J"
    ), 6),
    nutrient = rep(c(rep(NA, 16), "Y", "Y", "Y", "Y", "Z", "Z", "Z", "Z", "Y", "Y", "Y", "Z", "Z", "Z", "Y", "Y", "Z", "Z", "Y", "Z", "Y", "Z"), 6),
    p_g = rep(NA, 38 * 6),
    p_e = rep(NA, 38 * 6)
  )

  env_or_x <- c(220, 230, 700, 705, 710, 750)
  env_or_y <- c(660, 610, 450, 430, 510, 550)

  # genetic predispositions:
  x_g <- sample(1:1000, 38)
  y_g <- sample(1:1000, 38)

  # ecological availability:
  x_e <- sample(1:1000, 38)
  y_e <- sample(1:1000, 38)

  for (i in 1:6) {
    for (behav in 1:38) {
      output[output$population == list_pop[i] & output$behaviour == behav, ]$p_g <- 1 - sqrt((x_g[behav] - env_or_x[i])^2 + (y_g[behav] - env_or_y[i])^2) / 1000

      if (behav > 16) { # only for food-related behaviours:
        output[output$population == list_pop[i] & output$behaviour == behav, ]$p_e <- 1 - sqrt((x_e[behav] - env_or_x[i])^2 + (y_e[behav] - env_or_y[i])^2) / 500
      }
    }
  }

  # replace negative values with 0s:
  if (dim(output[output$p_g < 0, ])[1] > 0) {
    output[output$p_g < 0, ]$p_g <- 0
  }
  if (dim(output[output$p_e < 0 & !is.na(output$p_e), ])[1] > 0) {
    output[output$p_e < 0 & !is.na(output$p_e), ]$p_e <- 0
  }

  # return the tibble:
  output
}
```

This code does what we already did, but for all the 38 behaviours, and store everything in a 'tibble' structure, provided by the library `tidyverse`. In the main code, we just need to run the function to start the set-up of a simulation:

```{r}
oranzees_environment <- set_oranzees_environment()
```

We can explore the output simply writing the name of the data structure:

```{r}
oranzees_environment
```

Each line of the tibble **oranzees_environment** records the information for each behaviour, for each population. Since there are 38 behaviours and 6 populations, the tibble has 228 lines. You can notice that the values of $nutrient$ and $p_e$ for behaviours of the $social$ category are NA, that is "not available", which is what we described above.

There are a couple of checks that we can do to be sure that the function works as desired. First, we would expect, on average, genetic propensities being higher than ecological availabilities, and that it is more likely that some of the latter will be equal to zero. We can use the `facet` functionality in `ggplot` to split the data for the six populations. Here are the results for $p_g$:

```{r}
ggplot(data = oranzees_environment) +
  geom_point(aes(x = behaviour, y = p_g)) +
  facet_wrap(~population) +
  theme_bw() +
  labs(y = "Genetic propensity") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

We can do the same plot for $p_e$:

```{r warning=F}
ggplot(data = oranzees_environment) +
  geom_point(aes(x = behaviour, y = p_e)) +
  facet_wrap(~population) +
  theme_bw() +
  labs(y = "Ecological availability") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

As we wanted, values of $p_e$ are lower, and a few of them are zeros (also notice that the first 16 values for each population, on the left side of the plots, are not present as they are social behaviours). 

A second check exploits the fact that both $p_e$ and $p_g$ are assigned to the six populations following a geographical gradient. We would expect, thus, that populations that are geographically close to each other are also more similar genetically and they live in a similar environment. In other words, we expect for example populations 'Uossob' and 'Iat Forest' to be more similar one to each other than to populations 'Elabik' (or any of the others).

We can check this with some quick scatterplots. Here the correlation between the genetic propensities of populations 'Uossob' and 'Iat Forest' and 'Uossob' and 'Elabik':

```{r message=FALSE}
library(gridExtra)

p <- ggplot(mapping = aes(x = x, y = y)) + # basic scatterplot
  theme_bw() +
  xlim(0, 1) +
  ylim(0, 1) +
  coord_fixed()

data_to_plot <- tibble(x = oranzees_environment[oranzees_environment$population == "Uossob", ]$p_g, y = oranzees_environment[oranzees_environment$population == "Iat Forest", ]$p_g)
p1 <- p +
  geom_point(data = data_to_plot) +
  labs(x = "Uossob", y = "Iat Forest")

data_to_plot <- tibble(x = oranzees_environment[oranzees_environment$population == "Uossob", ]$p_g, y = oranzees_environment[oranzees_environment$population == "Elabik", ]$p_g)
p2 <- p +
  geom_point(data = data_to_plot) +
  labs(x = "Uossob", y = "Elabik")

grid.arrange(p1, p2, ncol = 2)
```

And the same for the the ecological availabilities of the 22 food-related behaviours:

```{r warning=FALSE}
data_to_plot <- tibble(x = oranzees_environment[oranzees_environment$population == "Uossob", ]$p_e, y = oranzees_environment[oranzees_environment$population == "Iat Forest", ]$p_e)
p1 <- p +
  geom_point(data = data_to_plot) +
  labs(x = "Uossob", y = "Iat Forest")

data_to_plot <- tibble(x = oranzees_environment[oranzees_environment$population == "Uossob", ]$p_e, y = oranzees_environment[oranzees_environment$population == "Elabik", ]$p_e)
p2 <- p +
  geom_point(data = data_to_plot) +
  labs(x = "Uossob", y = "Elabik")

grid.arrange(p1, p2, ncol = 2)
```

***

## The individuals

### Basic demography

Let's assume a population of $N=100$ individuals. This is a mock-up population that we will later use to model the real oranzees populations. We can assume that a time step $t$ of the simulation represents a month. Mortality is very simple: from when they are 25 years old, there is a 1% probability an oranzee will day each month, or they die when they are 60 years old (more complex version are possible: see e.g. Figure 3 in Hill et al., 2001). The number of individuals in the population is fixed, so each time an oranzee dies is replaced by a newborn. At the beginning the population is randomly initialised, with individuals between 0 and 25 years (i.e. 300 months) old.

Let's first initalise this population. We simply call $pop$ the data structure with individuals ages (notice we are using integers and not tibbles to speed up later the simulation):

```{r}
N <- 100
pop <- sample(1:300, N, replace = TRUE)
```

We can model this simple demography in this way. We fix $t_{max}=12000$, i.e. 1,000 years. To see what happens, we record some outputs, such as the average and the maximum age in the population.

```{r}
t_max <- 12000
output <- tibble(time = 1:t_max, av_age = rep(NA, t_max), max_age = rep(NA, t_max), juveniles = rep(NA, t_max))
for (t in 1:t_max) {
  pop <- pop + 1
  pop[pop >= 720] <- 0
  old <- which(pop > 300)
  dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
  pop[old[dead]] <- 0
  output$av_age[t] <- mean(pop)
  output$max_age[t] <- max(pop)
}
```

We can now plot the output to see how the age dynamics of our population look like:

```{r}
ggplot(data = output) +
  geom_line(aes(x = time, y = av_age / 12)) +
  labs(y = "Average age") +
  ylim(0, 30) +
  theme_bw()

ggplot(data = output) +
  geom_line(aes(x = time, y = max_age / 12)) +
  labs(y = "Maximum age") +
  theme_bw()
```

We can also visualise the age structure of the population when the simulation is finished: 

```{r}
tibble(age = pop) %>%
  ggplot(aes(x = age / 12)) +
  geom_histogram(binwidth = 5) +
  coord_flip() +
  labs(x = "Age", y = "Number of individuals") +
  theme_bw()
```


### Individual 'state'

The propensity to innovate is influenced by oranzees 'state'. For now, we focus on the social behaviours, as defined above. We assume that the propensity to innovate is based on how many of the four goals (each realised by having at least one behaviour in one of the four categories) are fulfilled. We need to modify the $pop$ structure to also record the behaviour that an individual possess, so we create a matrix, where the last column represents the age, and the other 38 columns all possible behaviours (this is handy so that the numbers of columns correspond to the numbers of behaviours:

```{r}
pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)
```

How do we calculate the state of an individual for social behaviours? An oranzee needs to have at least one among behaviours 1 to 4, one among 5 to 9, and so on. The state of the individual $1$ is thus: 

```{r}
state <- ((sum(pop[1, 1:4]) >= 1) + (sum(pop[1, 5:8]) >= 1) + (sum(pop[1, 9:12]) >= 1) + (sum(pop[1, 13:16]) >= 1)) / 4
```

Where $1$ means that all goals are fulfilled, and $0$ means that none of them are. At the beginning, all behaviours are $0$s, i.e. they are not possessed. We can call $p_{state}$ the probability to innovate influenced by the state of the individuals. This quantity is drawn from a normal distribution with mean equal to $1-state$ (meaning that the less goals are fulfilled the higher) and with a small standard deviation. This mean that even when all goals are fulfilled, that is the mean is zero, there is still some probability to innovate: 

```{r}
p_state <- rnorm(1, mean = 1 - state, sd = .05)
```

We can now iterate this process to all the population: 

```{r}
state <- rep(0, N)
p_state <- rep(NA, N)
for (i in 1:N) {
  state[i] <- ((sum(pop[i, 1:4]) >= 1) + (sum(pop[i, 5:8]) >= 1) + (sum(pop[i, 9:12]) >= 1) + (sum(pop[i, 13:16]) >= 1)) / 4
  p_state[i] <- rnorm(1, mean = 1 - state[i], sd = .05)
}
```

Let's have a look at $p_{state}$:

```{r}
head(p_state)
```

As we initalised all behaviours to zero, all the values of $p_{state}$ are, as expected, around one. This means that, at the beginning of the simulation (and at the beginning of their life) oranzees are highly likely to innovate. 

***

## Innovations

Having calculate $p_{state}$, we can now work on what oranzees will innovate. As explained above, all behaviours have a genetic propensity which influences the likelihood they are expressed by oranzees. In addition to this, we assume that what other individuals do also influence this propensity. We assume a linear relationship (notice we can simply change here to implement other kinds of frequency-dependent behaviours) between the number of individual present in the population showing a behaviour and its probability to innovate it. These values, let's call it $p_{peering}$, are drawn from a normal distribution of the total instances of each behaviour in the population. The normal distribution is useful because allows for non-observed behaviours (their frequency is equal to zero), to be anyway possible to be innovate (with low probability. The standard deviation value can be parametrised.) As standard deviations can be negative numbers, we replace them with $0$s, and then draw a possible innovation from this distribution.  

```{r}
p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
p_peering[p_peering < 0] <- 0
innovation_i <- sample(1:16, 1, prob = p_peering)
```

At this point, we use the information on $p_g$, the genetic propensity. We can use the tibble **oranzees_environment** we created before to retrieve these values. Let's use, for the mock-up population, the values used for 'Uossob'.

```{r}
test_environment <- oranzees_environment %>%
  filter(population == "Uossob")
```

The probability to actually innovate a behaviour is given by its genetic propensity:

```{r}
p_innovate <- test_environment$p_g[innovation_i]
```

Let's put together, as we did for the state, how the population code for innovations looks like:

```{r}
innovation_i <- rep(0, N)
p_innovate <- rep(NA, N)
for (i in 1:N) {
  p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
  p_peering[p_peering < 0] <- 0
  innovation_i[i] <- sample(1:16, 1, prob = p_peering)
  p_innovate[i] <- test_environment$p_g[innovation_i[i]]
}
```

***

## Population dynamics

At this point, we can wrap all together in a function, and see what happens to our mock-up population. We declare again the variables we are interested in, and re-initialise all the data structures, to be sure in case we changed something before. We create a variable `output` to store the information we are interested for now, that is, the frequencies of all 16 behaviours through time. The only difference in the code is the part that follow a successful innovation, i.e. after `if( runif(1) < test_environment$p_g[innovation_i])`: we assume here that a behaviour innovated in a specific category ('play', etc.) will replace the previous behaviour present there (this is the only way behaviours are discarded in the model).

```{r}
test_oranzees1 <- function(t_max) {
  oranzees_environment <- set_oranzees_environment()
  test_environment <- oranzees_environment %>%
    filter(population == "Uossob")

  N <- 100

  pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)

  output <- matrix(nrow = t_max, ncol = 16)

  for (t in 1:t_max) {
    output[t, ] <- colSums(pop[, 1:16])
    # demographic bit:
    pop[, 39] <- pop[, 39] + 1
    pop[pop[, 39] >= 720, ] <- 0
    old <- which(pop[, 39] > 300)
    dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
    pop[old[dead], ] <- 0
    # innovation bit:
    for (i in 1:N) {
      state <- ((sum(pop[i, 1:4]) >= 1) + (sum(pop[i, 5:8]) >= 1) + (sum(pop[i, 9:12]) >= 1) + (sum(pop[i, 13:16]) >= 1)) / 4
      p_state <- rnorm(1, mean = 1 - state, sd = 0.05)
      if (runif(1) < p_state) {
        p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
        p_peering[p_peering < 0] <- 0
        innovation_i <- sample(1:16, 1, prob = p_peering)
        if (runif(1) < test_environment$p_g[innovation_i]) {
          if (innovation_i <= 4) {
            pop[i, 1:4] <- 0
            pop[i, innovation_i] <- 1
          } else if (innovation_i > 4 & innovation_i <= 8) {
            pop[i, 5:8] <- 0
            pop[i, innovation_i] <- 1
          } else if (innovation_i > 8 & innovation_i <= 12) {
            pop[i, 9:12] <- 0
            pop[i, innovation_i] <- 1
          } else {
            pop[i, 13:16] <- 0
            pop[i, innovation_i] <- 1
          }
        }
      }
    }
  }
  output
}
```

To run the function, we call it, and store the output in a new data structure `my_test`. The function has one parameter, $t_{max}$, the number of time steps (months) we want the simulation to run.

```{r}
t_max <- 12000
my_test <- test_oranzees1(t_max)
```

We can rearrange the data and plot them:

```{r warning=FALSE}
my_test <- gather(as_tibble(my_test), 1:16, key = "behaviour", value = "frequency")
data_to_plot <- tibble(
  behaviour = my_test$behaviour,
  frequency = my_test$frequency,
  time = rep(1:t_max, 16),
  category = as_factor(c(rep("play", t_max * 4), rep("display", t_max * 4), rep("groom", t_max * 4), rep("courthsip", t_max * 4)))
)

ggplot(data = data_to_plot) +
  geom_line(aes(x = time, y = frequency, color = behaviour)) +
  facet_wrap(~category) +
  theme_bw() +
  theme(legend.position = "none")
```

The results look promising: usually, only one behaviour for each group reaches quasi-fixation, but, in the same time, there is space for some variability. 

### The effect of genetic propensity

An interesting question, at this point, is whether the successful behaviours in the various categories are determined mainly (or only) by the genetic propensity associated to them. A way to check this is rerun the simulation several time in the same 'environment', which includes also the values of $p_g$ and see if the results differ.

In order to do that, we need to slightly modify the function `test_oranzees1()`, which includes the initalisation of the environment (we do not want this any more, but we want to initalise it only once, before running different runs of the simulation), and to change its output, as we only need the final frequency of the behaviours, and not all their history. Here the new function `test_oranzees2()`:

```{r}
test_oranzees2 <- function(t_max) {
  N <- 100
  pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)

  for (t in 1:t_max) {

    # demographic bit:
    pop[, 39] <- pop[, 39] + 1
    pop[pop[, 39] >= 720, ] <- 0
    old <- which(pop[, 39] > 300)
    dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
    pop[old[dead], ] <- 0
    # innovation bit:
    for (i in 1:N) {
      state <- ((sum(pop[i, 1:4]) >= 1) + (sum(pop[i, 5:8]) >= 1) + (sum(pop[i, 9:12]) >= 1) + (sum(pop[i, 13:16]) >= 1)) / 4
      p_state <- rnorm(1, mean = 1 - state, sd = 0.05)
      if (runif(1) < p_state) {
        p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
        p_peering[p_peering < 0] <- 0
        innovation_i <- sample(1:16, 1, prob = p_peering)
        if (runif(1) < test_environment$p_g[innovation_i]) {
          if (innovation_i <= 4) {
            pop[i, 1:4] <- 0
            pop[i, innovation_i] <- 1
          } else if (innovation_i > 4 & innovation_i <= 8) {
            pop[i, 5:8] <- 0
            pop[i, innovation_i] <- 1
          } else if (innovation_i > 8 & innovation_i <= 12) {
            pop[i, 9:12] <- 0
            pop[i, innovation_i] <- 1
          } else {
            pop[i, 13:16] <- 0
            pop[i, innovation_i] <- 1
          }
        }
      }
    }
  }
  output <- colSums(pop[, 1:16])
}
```

For our test we first initalise once `oranzees_environment`, and then we run 10 times the simulation.

```{r eval=FALSE}
oranzees_environment <- set_oranzees_environment()
test_environment <- oranzees_environment %>%
  filter(population == "Uossob")

n_run <- 10
t_max <- 12000
gene_test1 <- matrix(nrow = n_run, ncol = 16)
for (run in 1:n_run) {
  gene_test1[run, ] <- test_oranzees2(t_max)
}

write(t(gene_test1), file = "output/gene_test1.csv", ncolumns = 16)
write(test_environment$p_g[1:16], file = "output/gene_test1_p_g.csv", ncolumns = 1)
```

To save time, we do not run this bit each time (see the instruction `{r eval=FALSE}`). This simulation has been run only once and the results have been saved in an external file with the function `write()`. We can load the data and print the result:

```{r message=FALSE}
library(reshape2)
results <- as.matrix(read.table("output/gene_test1.csv"))
colnames(results) <- 1:16

as_tibble(melt(results, varnames = c("run", "behaviour"), value.name = "frequency")) %>%
  mutate(run = as_factor(run), behaviour = as_factor(behaviour)) %>%
  add_column(category = as_factor(c(rep("play", 40), rep("display", 40), rep("groom", 40), rep("courthsip", 40)))) %>%
  ggplot() +
  geom_raster(aes(x = behaviour, y = run, fill = frequency)) +
  facet_wrap(~category, scales = "free") +
  scale_fill_gradient(low = "grey90", high = "red") +
  theme_bw()
```

The winning behaviours are generally similar in different runs with the same set-up of `oranzees_environment`, showing the effect of the initalisation of $p_g$. We can check it directly, and see whether the winning behaviours are indeed the ones with higher $p_g$:

```{r}
genes <- read.table("output/gene_test1_p_g.csv")
tibble(p_g = genes$V1, total = colSums(results), category = as_factor(c(rep("play", 4), rep("display", 4), rep("groom", 4), rep("courthsip", 4)))) %>%
  ggplot(aes(y = total, x = p_g)) +
  geom_point() +
  facet_wrap(~category) +
  theme_bw()
```

This is not a surprising result, as genetic propensity is the only directional force in the model, and still variability is possible, given random small initial difference amplified by the effects of the observations of other individuals.

***

**NOTE:**
Two parameters that may be interesting to study in an advanced version of the model:

* The weight of $p_g$. I have not decided yet how to implement it. Less effect of $p_g$ should make different runs with the same initial set-up more different between each other than what we have now. It should also make more variable the frequency of behaviours within a single run, as the only force acting is an analogous of drift (so less weights of genes would produce, understandably, less stable 'cultures').  

* The standard deviation in: `p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)` now fixed to $1$. This has a role similar to 'noise' in oranzees' observations, especially important for behaviours at lower frequencies. Lower values of the standard deviation should make runs more stable. In particular, lower values should create stable 'cultures' even when the effect of $g_p$ is lower.

***





