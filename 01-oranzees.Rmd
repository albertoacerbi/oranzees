---
title: "Oranzees model (01)"
author: "Alberto Acerbi"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This R markdown file documents the development of the Oranzees model. The code-only version to run the model is in the file [main.R](main.R) in the same repository.

## Spatial set-up

We first need to set-up a simulated environment where six populations of oranzees live at relative distances that are approximately similar to the six populations of chimpanzees described in Whiten et al., 1999. 

We use the R package [`imager`](https://dahtah.github.io/imager/imager.html) to process a capture from Figure 1 in Whiten et al., 1999.

```{r message = FALSE}
library(imager)
chimp_env <- load.image("material/Whiten_1999_cap.png")
plot(chimp_env)
box()
```

We manually process the image to have only the six points to which we are interested, and we also reverse the y-axis (in image processing starting from zero and go negative is standard, but this is not useful for us):

```{r}
chimp_env <- load.image("material/Whiten_1999_cap2.png")
plot(chimp_env, axes = F)
axis(1)
axis(2, at = seq(-100, 400, 100), labels = seq(500, 0, -100))
grid()
box()
```

Here are the approximate locations of the oranzees populations:

```{r}
env_or_x <- c(420, 430, 900, 905, 910, 950)
env_or_y <- c(360, 310, 150, 130, 210, 250)

plot(env_or_x, env_or_y, xlim = c(0, 1200), ylim = c(0, 500), pch = 21, bg = "red")
grid()
```

Just for visualisation purposes, here a plot with the same locations overimposed to a map of the imaginary 'Pongogea', where oranzees live. Notice the command `-env_or_y + 400` which move back to y coordinates to the reversed y-axis. The names of the sites are the reversed version of the names in Whiten et al., 1999 (e.g. 'Uossob' = 'Bossou', etc.)

```{r}
pongogea <- load.image("material/pongogea_cap.png")
plot(pongogea)
points(env_or_x, -env_or_y + 400, pch = 21, bg = "red", cex = 0.5)

text(100, 30, "Uossob", font = 2, cex = 0.9)
segments(180, 30, env_or_x[1], -env_or_y[1] + 400)

text(120, 270, "Iat Forest", font = 2, cex = 0.9)
segments(210, 270, env_or_x[2], -env_or_y[2] + 400)

text(540, 270, "Ebmog", font = 2, cex = 0.9)
segments(600, 270, env_or_x[3], -env_or_y[3] + 400)

text(1200, 270, "Elaham", font = 2, cex = 0.9)
segments(1120, 270, env_or_x[4], -env_or_y[4] + 400)

text(540, 30, "Elabik", font = 2, cex = 0.9)
segments(600, 30, env_or_x[5], -env_or_y[5] + 400)

text(1220, 30, "Ognodub", font = 2, cex = 0.9)
segments(1120, 30, env_or_x[6], -env_or_y[6] + 400)
```

For modelling convenience, we put these locations approximately in the centre of a 1000,1000 squared environment (what is important are the relative distances, not their absolute values):

```{r}
env_or_x <- env_or_x - 200
env_or_y <- env_or_y + 300

par(pty = "s")
plot(env_or_x, env_or_y, xlim = c(0, 1000), ylim = c(0, 1000), pch = 21, bg = "red")
grid()
```

***

## The behaviours

Following again Whiten et al., 1999, we consider 64 possible behaviours (instead of the 65 in the original). We distinguish among 32 'social' and 32'food-related' behaviours.

### Genetic propensity

We first implement the idea that the probability to acquire any of these behaviours depends (among other things) by what we call 'genetic propensity', and we model as a probability $p_g(0,1)$.

**TO DO**

These probability is assigned randomly and independently to each behaviours. To assign it to the different populations we use a geographical gradient. For each behaviour, a random point is chosen in the Cartesian space and its distance to each population is calculated. 

Here an example:

```{r}
# generate the random point for the genetic propensity:
x_g <- sample(1:1000, 1)
y_g <- sample(1:1000, 1)

# calcualte the distance from the six populations:
d_g <- c()
for (i in 1:6) {
  d_g[i] <- sqrt((x_g - env_or_x[i])^2 + (y_g - env_or_y[i])^2)
}
```

Now we can see the random point we extracted:

```{r echo=FALSE}
c(x_g, y_g)
```

And the distances calculated:

```{r echo=FALSE}
d_g
```

Now we can rescale these values, using the function `rescale()` from the library `scales`. To tune the importance of genetic propensity we use a parameter $\alpha_g$ that tells us the range of the output. If $\alpha_g=1$ the range is maximum: the highest distance is rescaled to $1$ and the lowest to $0$. Intermediate values give less effect to genetic propensity, until$\alpha_g=0.5$ that produces all probabilities equal to $0.5$. We finally calculated the actual probability as $1$ minus the rescaled values. We can start with a limited effect of genetic propensity, for example, $\alpha_g=.7$:    

```{r}
library(scales)
alpha_g <- 0.7
d_g_rescaled <- rescale(d_g, to = c(1 - alpha_g, alpha_g))
p_g <- 1 - d_g_rescaled
```

Here are the final values for $p_g$:

```{r echo=FALSE}
p_g
```

An intuitive way to see this graphically is to use a gradient. The code is slightly more complicated, but we just need to run it once to visualise the effect. We first calculate the values of $p_g$ for all the points in the environment:

```{r}
gradient_g <- matrix(nrow = 1000, ncol = 1000)

for (i in 1:1000) {
  for (j in 1:1000) {
    gradient_g[i, j] <- sqrt((x_g - i)^2 + (y_g - j)^2)
  }
}
gradient_g <- 1 - rescale(gradient_g, to = c(1 - alpha_g, alpha_g), from = c(min(d_g), max(d_g)))
gradient_g[gradient_g > 1] <- 1
gradient_g[gradient_g < 0] <- 0
```

And we then plot it, using the R package [`viridis`](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html), for the colour scale.

```{r message = FALSE}
library(viridis)
par(pty = "s")
image(1:1000, 1:1000, gradient_g, col = viridis(10), xlab = "env_or_x", ylab = "env_or_y")
contour(1:1000, 1:1000, gradient_g, add = TRUE)
points(env_or_x, env_or_y, pch = 21, bg = "red")
```

We can check that the $p_g$ values of the six different populations look like the ones we showed above, just before working on the visualisation (the order of the populations is from left to right on the x-axis). Remember, this means that population with higher values will be more genetically predisposed to acquire one of the 38 behaviours.

### Ecological availability

We define, together with genetic propensity, a similar variable $p_e(0,1)$, standing for ecological availability. Whereas the likelihood of acquiring all beahviours depends on $p_g$, ecological availability has influence only on food-related behaviours. Ecological availability can be thought as the probability of finding a resource, or its nutritional values, in one of the site.

Ecological availability is implemented as genetic propensity, but we have a different parameter, $\alpha_e$, to rescale it. We start by assuming a stronger effect of ecological availability, so we fix $\alpha_e=0.9$.

```{r}
x_e <- sample(1:1000, 1)
y_e <- sample(1:1000, 1)

d_e <- c()
for (i in 1:6) {
  d_e[i] <- sqrt((x_e - env_or_x[i])^2 + (y_e - env_or_y[i])^2)
}

alpha_e <- 0.9
d_e_rescaled <- rescale(d_e, to = c(1 - alpha_e, alpha_e))
p_e <- 1 - d_e_rescaled
```

As before, here are the final values for $p_e$:

```{r echo=FALSE}
p_e
```

And we can visualise them, using the same technique:

```{r}
gradient_e <- matrix(nrow = 1000, ncol = 1000)

for (i in 1:1000) {
  for (j in 1:1000) {
    gradient_e[i, j] <- sqrt((x_e - i)^2 + (y_e - j)^2)
  }
}
gradient_e <- 1 - rescale(gradient_e, to = c(1 - alpha_e, alpha_e), from = c(min(d_e), max(d_e)))
gradient_e[gradient_e > 1] <- 1
gradient_e[gradient_e < 0] <- 0

par(pty = "s")
image(1:1000, 1:1000, gradient_e, col = magma(10), xlab = "env_or_x", ylab = "env_or_y")
contour(1:1000, 1:1000, gradient_e, add = TRUE)
points(env_or_x, env_or_y, pch = 21, bg = "red")
```

Again, we can check that the values in the plot correspond to the ones calculated above. The difference between the plot for genetic propensity and the plot for ecological availability illustrates the effect of the parameter $\alpha$. 

### Categories of behaviours

We model the idea that different behaviours can serve the same goal, so that if behaviour $1$ and $2$ serve the same goal, an individual performing $1$ will be unlikely to also perform $2$. 

In the case of social behaviours, we assume four categories of behaviours, each with four possible different behaviours, that serve the same goal, as illustrated here (notice the categories' names are purely indicative):

Category  |    |    |    | 
--------- |----|----|----|----
play      | 1  | 2  | 3  | 4
display   | 5  | 6  | 7  | 8
groom     | 9  | 10 | 11 | 12
courtship | 13 | 14 | 15 | 16

We do the same for food-related behaviours, with the difference that, for each 'goal' there is a variable number of behaviours, as such:

Category |    |    |    | 
---------|----|----|----|----
A        | 17 | 18 | 19 | 20
B        | 21 | 22 | 23 | 24
C        | 25 | 26 | 27 | 
D        | 28 | 29 | 30 | 
E        | 31 | 32 |    |
F        | 33 | 34 |    |
G        | 35 |    |    |
H        | 36 |    |    |
I        | 37 |    |    |
J        | 38 |    |    |

In addition, the categories of food-related behaviours are associated to two different 'nutrients'. The idea is that individuals need to balance their nutritional intake, so that their optimal diet consist in a roughly equal number of foodstuff for one and the other nutrient. Our final classification of food-related behaviours is:

Category |    |    |    |    | Nutrient
---------|----|----|----|----|---------
A        | 17 | 18 | 19 | 20 |    Y
B        | 21 | 22 | 23 | 24 |    Z
C        | 25 | 26 | 27 |    |    Y
D        | 28 | 29 | 30 |    |    Z
E        | 31 | 32 |    |    |    Y
F        | 33 | 34 |    |    |    Z
G        | 35 |    |    |    |    Y
H        | 36 |    |    |    |    Z
I        | 37 |    |    |    |    Y
J        | 38 |    |    |    |    Z 

***

## Setting-up the environment

We can now wrap everything up in a function `set_oranzees_world()` that can be used independently from what we done so far, and that we will use in the code of the actual model (*main.R*):

```{r message=FALSE}
library(tidyverse)
library(scales)

set_oranzees_world <- function(alpha_g, alpha_e) {
  list_pop <- c("Uossob", "Iat Forest", "Ebmog", "Elaham", "Elabik", "Ognodub")
  output <- tibble(
    population = rep(list_pop, each = 38),
    behaviour = as.factor(rep(1:38, 6)),
    type = rep(c(rep("social", 16), rep("food-related", 22)), 6),
    category = rep(c(
      rep("play", 4), rep("display", 4), rep("groom", 4), rep("courthsip", 4),
      "A", "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "D", "D", "D", "E", "E", "F", "F", "G", "H", "I", "J"
    ), 6),
    nutrient = rep(c(rep(NA, 16), "Y", "Y", "Y", "Y", "Z", "Z", "Z", "Z", "Y", "Y", "Y", "Z", "Z", "Z", "Y", "Y", "Z", "Z", "Y", "Z", "Y", "Z"), 6),
    p_g = rep(NA, 38 * 6),
    p_e = rep(NA, 38 * 6)
  )

  env_or_x <- c(220, 230, 700, 705, 710, 750)
  env_or_y <- c(660, 610, 450, 430, 510, 550)

  # genetic predispositions:
  x_g <- sample(1:1000, 38)
  y_g <- sample(1:1000, 38)

  # ecological availability:
  x_e <- sample(1:1000, 38)
  y_e <- sample(1:1000, 38)
  
  for(behav in 1:38){
    output[output$behaviour == behav,]$p_g <- 1 - rescale(sqrt((x_g[behav] - env_or_x)^2 + (y_g[behav] - env_or_y)^2), to = c(1 - alpha_g, alpha_g))
    
    if(behav > 16){
          output[output$behaviour == behav,]$p_e <- 1 - rescale(sqrt((x_e[behav] - env_or_x)^2 + (y_e[behav] - env_or_y)^2), to = c(1 - alpha_e, alpha_e))
    }
  }
  # return the tibble:
  output
}
```

This code does what we already did, but for all the 38 behaviours, and store everything in a 'tibble' structure, provided by the library `tidyverse`. In the main code, we just need to run the function to start the set-up of a simulation:

```{r}
alpha_g = 0.7
alpha_e = 0.9
oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
```

We can explore the output simply writing the name of the data structure:

```{r}
oranzees_world
```

Each line of the tibble **oranzees_world** records the information for each behaviour, for each population. Since there are 38 behaviours and 6 populations, the tibble has 228 lines. You can notice that the values of $nutrient$ and $p_e$ for behaviours of the $social$ category are NA, that is "not available", which is what we described above.

***

## The individuals

### Basic demography

Let's assume a population of $N=100$ individuals. This is a mock-up population that we will later use to model the real oranzees populations. We can assume that a time step $t$ of the simulation represents a month. Mortality is very simple: from when they are 25 years old, there is a 1% probability an oranzee will day each month, or they die when they are 60 years old (more complex version are possible: see e.g. Figure 3 in Hill et al., 2001). The number of individuals in the population is fixed, so each time an oranzee dies is replaced by a newborn. At the beginning the population is randomly initialised, with individuals between 0 and 25 years (i.e. 300 months) old.

Let's first initalise this population. We simply call $pop$ the data structure with individuals ages (notice we are using integers and not tibbles to speed up later the simulation):

```{r}
N <- 100
pop <- sample(1:300, N, replace = TRUE)
```

We can model this simple demography in this way. We fix $t_{max}=12000$, i.e. 1,000 years. To see what happens, we record some outputs, such as the average and the maximum age in the population.

```{r}
t_max <- 12000
output <- tibble(time = 1:t_max, av_age = rep(NA, t_max), max_age = rep(NA, t_max), juveniles = rep(NA, t_max))
for (t in 1:t_max) {
  pop <- pop + 1
  pop[pop >= 720] <- 0
  old <- which(pop > 300)
  dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
  pop[old[dead]] <- 0
  output$av_age[t] <- mean(pop)
  output$max_age[t] <- max(pop)
}
```

We can now plot the output to see how the age dynamics of our population look like:

```{r}
ggplot(data = output) +
  geom_line(aes(x = time, y = av_age / 12)) +
  labs(y = "Average age") +
  ylim(0, 30) +
  theme_bw()

ggplot(data = output) +
  geom_line(aes(x = time, y = max_age / 12)) +
  labs(y = "Maximum age") +
  theme_bw()
```

We can also visualise the age structure of the population when the simulation is finished: 

```{r}
tibble(age = pop) %>%
  ggplot(aes(x = age / 12)) +
  geom_histogram(binwidth = 5) +
  coord_flip() +
  labs(x = "Age", y = "Number of individuals") +
  theme_bw()
```


### Individual 'state'

The propensity to innovate is influenced by oranzees 'state'. For now, we focus on the social behaviours, as defined above. We assume that the propensity to innovate is based on how many of the four goals (each realised by having at least one behaviour in one of the four categories) are fulfilled (notice the state is calculated between categories, so it may happen that an oranzee that fulfilled, say, only the category of 'play', will have high probability to innovate, including behaviours in the fulfilled category. This is reasonable for food-related behaviours, where oranzees do not know what nutrients foods are providing, but it is a simplification for social behaviours). We need to modify the $pop$ structure to also record the behaviour that an individual possess, so we create a matrix, where the last column represents the age, and the other 38 columns all possible behaviours (this is handy so that the numbers of columns correspond to the numbers of behaviours:

```{r}
pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)
```

How do we calculate the state of an individual for social behaviours? An oranzee needs to have at least one among behaviours 1 to 4, one among 5 to 9, and so on. The state of the individual $1$ is thus: 

```{r}
state <- ((sum(pop[1, 1:4]) >= 1) + (sum(pop[1, 5:8]) >= 1) + (sum(pop[1, 9:12]) >= 1) + (sum(pop[1, 13:16]) >= 1)) / 4
```

Where $1$ means that all goals are fulfilled, and $0$ means that none of them are. At the beginning, all behaviours are $0$s, i.e. they are not possessed. We can call $p_{state}$ the probability to innovate influenced by the state of the individuals. This quantity is drawn from a normal distribution with mean equal to $1-state$ (meaning that the less goals are fulfilled the higher) and with a small standard deviation. This mean that even when all goals are fulfilled, that is the mean is zero, there is still some probability to innovate: 

```{r}
p_state <- rnorm(1, mean = 1 - state, sd = .05)
```

We can now iterate this process to all the population: 

```{r}
state <- rep(0, N)
p_state <- rep(NA, N)
for (i in 1:N) {
  state[i] <- ((sum(pop[i, 1:4]) >= 1) + (sum(pop[i, 5:8]) >= 1) + (sum(pop[i, 9:12]) >= 1) + (sum(pop[i, 13:16]) >= 1)) / 4
  p_state[i] <- rnorm(1, mean = 1 - state[i], sd = .05)
}
```

Let's have a look at $p_{state}$:

```{r}
head(p_state)
```

As we initalised all behaviours to zero, all the values of $p_{state}$ are, as expected, around one. This means that, at the beginning of the simulation (and at the beginning of their life) oranzees are highly likely to innovate. 

***

## Innovations

Having calculate $p_{state}$, we can now work on what oranzees will innovate. As explained above, all behaviours have a genetic propensity which influences the likelihood they are expressed by oranzees. In addition to this, we assume that what other individuals do also influence this propensity. We assume a linear relationship (notice we can simply change here to implement other kinds of frequency-dependent behaviours) between the number of individual present in the population showing a behaviour and its probability to innovate it. These values, let's call it $p_{peering}$, are drawn from a normal distribution of the total instances of each behaviour in the population. The normal distribution is useful because allows for non-observed behaviours (their frequency is equal to zero), to be anyway possible to be innovate (with low probability. The standard deviation value can be parametrised.) As standard deviations can be negative numbers, we replace them with $0$s, and then draw a possible innovation from this distribution.  

```{r}
p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
p_peering[p_peering < 0] <- 0
innovation_i <- sample(1:16, 1, prob = p_peering)
```

At this point, we use the information on $p_g$, the genetic propensity. We can use the tibble **oranzees_world** we created before to retrieve these values. Let's use, for the mock-up population, the values used for 'Uossob'.

```{r}
test_world <- oranzees_world %>%
  filter(population == "Uossob")
```

The probability to actually innovate a behaviour is given by its genetic propensity:

```{r}
p_innovate <- test_world$p_g[innovation_i]
```

Let's put together, as we did for the state, how the population code for innovations looks like:

```{r}
innovation_i <- rep(0, N)
p_innovate <- rep(NA, N)
for (i in 1:N) {
  p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
  p_peering[p_peering < 0] <- 0
  innovation_i[i] <- sample(1:16, 1, prob = p_peering)
  p_innovate[i] <- test_world$p_g[innovation_i[i]]
}
```

***

## Population dynamics

At this point, we can wrap all together in a function, and see what happens to our mock-up population. We declare again the variables we are interested in, and re-initialise all the data structures, to be sure in case we changed something before. We create a variable `output` to store the information we are interested for now, that is, the frequencies of all 16 behaviours through time. 

```{r}
test_oranzees1 <- function(t_max, alpha_g, alpha_e) {
  oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
  test_world <- oranzees_world %>%
    filter(population == "Uossob")

  N <- 100

  pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)

  output <- matrix(nrow = t_max, ncol = 16)

  for (t in 1:t_max) {
    output[t, ] <- colSums(pop[, 1:16])
    # demographic bit:
    pop[, 39] <- pop[, 39] + 1
    pop[pop[, 39] >= 720, ] <- 0
    old <- which(pop[, 39] > 300)
    dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
    pop[old[dead], ] <- 0
    # innovation bit:
    for (i in 1:N) {
      state <- ((sum(pop[i, 1:4]) >= 1) + (sum(pop[i, 5:8]) >= 1) + (sum(pop[i, 9:12]) >= 1) + (sum(pop[i, 13:16]) >= 1)) / 4
      p_state <- rnorm(1, mean = 1 - state, sd = 0.05)
      if (runif(1) < p_state) {
        p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
        p_peering[p_peering < 0] <- 0
        innovation_i <- sample(1:16, 1, prob = p_peering)
        if (runif(1) < test_world$p_g[innovation_i]) {
          pop[i, innovation_i] <- 1
        }
      }
    }
  }
  output
}
```

To run the function, we call it, and store the output in a new data structure `my_test`. The function has three parameters, $t_{max}$, the number of time steps (months) we want the simulation to run, and $\alpha_g$ and $\alpha_e$, explained before.

```{r}
t_max <- 12000
my_test <- test_oranzees1(t_max, alpha_g, alpha_e)
```

We can rearrange the data and plot them:

```{r warning=FALSE}
my_test <- gather(as_tibble(my_test), 1:16, key = "behaviour", value = "frequency")
data_to_plot <- tibble(
  behaviour = my_test$behaviour,
  frequency = my_test$frequency,
  time = rep(1:t_max, 16),
  category = as_factor(c(rep("play", t_max * 4), rep("display", t_max * 4), rep("groom", t_max * 4), rep("courthsip", t_max * 4)))
)

ggplot(data = data_to_plot) +
  geom_line(aes(x = time, y = frequency, color = behaviour)) +
  facet_wrap(~category) +
  theme_bw() +
  theme(legend.position = "none")
```


### The effect of genetic propensity

An interesting question, at this point, is whether the successful behaviours in the various categories are determined mainly (or only) by the genetic propensity associated to them. A way to check this is rerun the simulation several time in the same 'environment', which includes also the values of $p_g$ and see if the results differ.

In order to do that, we need to slightly modify the function `test_oranzees1()`, which includes the initalisation of the environment (we do not want this any more, but we want to initalise it only once, before running different runs of the simulation), and to change its output, as we only need the final frequency of the behaviours, and not all their history. Here the new function `test_oranzees2()`:

```{r}
test_oranzees2 <- function(t_max) {
  N <- 100
  pop <- matrix(c(rep(0, 38 * N), sample(1:300, N, replace = TRUE)), nrow = N, byrow = FALSE)

  for (t in 1:t_max) {

    # demographic bit:
    pop[, 39] <- pop[, 39] + 1
    pop[pop[, 39] >= 720, ] <- 0
    old <- which(pop[, 39] > 300)
    dead <- sample(c(TRUE, FALSE), length(old), prob = c(.01, .99), replace = TRUE)
    pop[old[dead], ] <- 0
    # innovation bit:
    for (i in 1:N) {
      state <- ((sum(pop[i, 1:4]) >= 1) + (sum(pop[i, 5:8]) >= 1) + (sum(pop[i, 9:12]) >= 1) + (sum(pop[i, 13:16]) >= 1)) / 4
      p_state <- rnorm(1, mean = 1 - state, sd = 0.05)
      if (runif(1) < p_state) {
        p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)
        p_peering[p_peering < 0] <- 0
        innovation_i <- sample(1:16, 1, prob = p_peering)
        if (runif(1) < test_world$p_g[innovation_i]) {
          pop[i, innovation_i] <- 1
        }
      }
    }
  }
  output <- colSums(pop[, 1:16])
}
```

For our test we first initalise once `oranzees_environment`, and then we run 10 times the simulation.

```{r eval=FALSE}
oranzees_world <- set_oranzees_world(alpha_g, alpha_e)
test_world <- oranzees_world %>%
  filter(population == "Uossob")

n_run <- 10
t_max <- 12000
gene_test1 <- matrix(nrow = n_run, ncol = 16)
for (run in 1:n_run) {
  gene_test1[run, ] <- test_oranzees2(t_max)
  print(run)
}

write(t(gene_test1), file = "output/social_test1.csv", ncolumns = 16)
write(test_world$p_g[1:16], file = "output/social_test1_p_g.csv", ncolumns = 1)
```

To save time, we do not run this bit each time (see the instruction `{r eval=FALSE}`). This simulation has been run only once and the results have been saved in an external file with the function `write()`. We can load the data and print the result:

```{r message=FALSE}
library(reshape2)
results <- as.matrix(read.table("output/social_test1.csv"))
colnames(results) <- 1:16

as_tibble(melt(results, varnames = c("run", "behaviour"), value.name = "frequency")) %>%
  mutate(run = as_factor(run), behaviour = as_factor(behaviour)) %>%
  add_column(category = as_factor(c(rep("play", 40), rep("display", 40), rep("groom", 40), rep("courthsip", 40)))) %>%
  ggplot() +
  geom_raster(aes(x = behaviour, y = run, fill = frequency)) +
  facet_wrap(~category, scales = "free") +
  scale_fill_gradient(low = "grey90", high = "red") +
  theme_bw()
```

The winning behaviours are generally similar in different runs with the same set-up of `oranzees_environment`, showing the effect of the initalisation of $p_g$. We can check it directly, and see whether the winning behaviours are indeed the ones with higher $p_g$:

```{r}
genes <- read.table("output/social_test1_p_g.csv")
tibble(p_g = genes$V1, total = colSums(results), category = as_factor(c(rep("play", 4), rep("display", 4), rep("groom", 4), rep("courthsip", 4)))) %>%
  ggplot(aes(y = total, x = p_g)) +
  geom_point() +
  facet_wrap(~category) +
  theme_bw()
```

This is not a surprising result, as genetic propensity is the only directional force in the model, and still variability is possible, given random small initial difference amplified by the effects of the observations of other individuals.

***

**NOTE:**
It may be interesting to study in an advanced version of the model:

* The weight of $p_g$ and $p_e$, by varying $\alpha_g$ and $\alpha_e$. Less effect of $p_g$ should make different runs with the same initial set-up more different between each other than what we have now. It should also make more variable the frequency of behaviours within a single run, as the only force acting is an analogous of drift (so less weights of genes would produce, understandably, less stable 'cultures').  

* The standard deviation in: `p_peering <- rnorm(16, mean = colSums(pop[, 1:16]), sd = 1)` now fixed to $1$. This has a role similar to 'noise' in oranzees' observations, especially important for behaviours at lower frequencies. Lower values of the standard deviation should make runs more stable. In particular, lower values should create stable 'cultures' even when the effect of $p_g$ is lower.

***

The documentation continues in [02-oranzees.html](02-oranzees.html)




